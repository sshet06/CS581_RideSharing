{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation steps\n",
    "\n",
    "\n",
    "### 1.Install the latest JRE and get GraphHopper Server as zip from <a href=https://graphhopper.com/public/releases/graphhopper-web-0.10.3-bin.zip>Graphhopper API</a>. Unzip it.\n",
    "### 2.Copy this OSM file into the SAME unzipped directory: <a href=https://download.geofabrik.de/north-america/us/new-york-latest.osm.pbf >new-york-latest.osm.pbf</a>\n",
    "### 3.Start GraphHopper Maps via: java -jar graphhopper-web-0.10.3-with-dep.jar jetty.resourcebase=webapp config=config-example.properties datareader.file=new-york-latest.osm.pbf. \n",
    "### 3.Test to see if its running after you see 'Started server at HTTP 8989' by going to http://localhost:8989/ and you should see a map of New York.\n",
    "### 4.Keep this running when executing our program because this is the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance = 1049.667\n",
      "Time = 111745\n"
     ]
    }
   ],
   "source": [
    "# Check how graphhopper works\n",
    "a,b,c,d = df['pickup_latitude'].loc[1],df['pickup_longitude'].loc[1],df['dropoff_latitude'].loc[1],df['dropoff_longitude'].loc[1]\n",
    "request_str = 'http://localhost:8989/route?point=' + str(a) + '%2C' + str(b) + '&point=' + str(c) + '%2C' + str(d) + '&vehicle=car'\n",
    "request = Request(request_str)\n",
    "res=requests.get(request_str)\n",
    "print(\"Distance = {}\".format(json.loads(res.text)['paths'][0]['distance']))\n",
    "print(\"Time = {}\".format(json.loads(res.text)['paths'][0]['time']))\n",
    "# Distance = 1158.322\n",
    "# Time = 128375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from h3 import h3\n",
    "import json\n",
    "from urllib.request import URLError, Request, urlopen\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(dataframe,pool_time_window):\n",
    "    a,b,c,d=[],[],[],[]\n",
    "    df_distance =  pd.DataFrame(columns = ['pickup_h3','dropoff_h3','distance','duration'])\n",
    "    for node_a, node_b in list(permutations(dataframe.index, 2)):\n",
    "        temp_curr, temp_next = [], []\n",
    "\n",
    "        from_location = dataframe.iloc[node_a]['pickup_h3']\n",
    "        to_location = dataframe.iloc[node_b]['pickup_h3']\n",
    "\n",
    "        e, f, g, h = dataframe.iloc[node_a]['pickup_latitude'], dataframe.iloc[node_a]['pickup_longitude'],\\\n",
    "        dataframe.iloc[node_b]['pickup_latitude'],dataframe.iloc[node_b]['pickup_longitude']\n",
    "        \n",
    "        request_str = 'http://localhost:8989/route?point=' + str(e) + '%2C' + str(f) + '&point=' + str(\n",
    "            g) + '%2C' + str(h) + '&vehicle=car'\n",
    "        request = Request(request_str)\n",
    "        res = requests.get(request_str)\n",
    "        distance = json.loads(res.text)['paths'][0]['distance']\n",
    "\n",
    "        time = json.loads(res.text)['paths'][0]['time']\n",
    "        minute, msec = divmod(time, 60000)\n",
    "        if (distance / 1609.344) <=3:\n",
    "            a.append(from_location)\n",
    "            b.append(to_location)\n",
    "            c.append(distance / 1609.344)  # convert meters to miles\n",
    "            d.append(minute + (msec / 100000))  # convert ms to s and add to min\n",
    "\n",
    "    df_distance['pickup_h3'] = a\n",
    "    df_distance['dropoff_h3'] = b\n",
    "    df_distance['distance'] = c\n",
    "    df_distance['duration'] = d\n",
    "    return df_distance\n",
    "# df_distance = df_distance.set_index(['pickup_h3','dropoff_h3'])\n",
    "# df_distance.to_csv('29jan2016_30jan2016.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the below cell only if distance is not precomputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(pool_time_window,df):\n",
    "    final_distance=[]\n",
    "    for _,trips in df.groupby(['pool_window']):\n",
    "        trips = trips.reset_index()\n",
    "        df_distance=  get(trips,pool_time_window)\n",
    "        final_distance.append(df_distance)\n",
    "    df_distance = pd.concat(final_distance)\n",
    "    df_distance.reset_index(drop=True,inplace=True) \n",
    "    df_distance.to_csv('17may2016.csv')\n",
    "    return df_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The nodes of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,idx,data):\n",
    "        self.id = idx\n",
    "        self.pickup_location = (data.pickup_latitude,data.pickup_longitude,data.pickup_h3)\n",
    "        self.dropoff_location = (data.dropoff_latitude,data.dropoff_longitude,data.dropoff_h3)\n",
    "        self.pickup_time = data.pickup_time\n",
    "        self.dropoff_time = data.dropoff_time\n",
    "        self.distance = data.trip_distance\n",
    "        self.duration = data.duration\n",
    "        self.delay = data.delay\n",
    "        self.passenger_count = data.passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_duration(node_a,node_b,trip_type):\n",
    "    if trip_type==2: \n",
    "        e, f, g, h = node_a.pickup_location[0], node_a.pickup_location[1], node_b.pickup_location[0],node_b.pickup_location[1]\n",
    "    else:\n",
    "        pass\n",
    "        #TBD\n",
    "    request_str = 'http://localhost:8989/route?point=' + str(e) + '%2C' + str(f) + '&point=' + str(\n",
    "        g) + '%2C' + str(h) + '&vehicle=car'\n",
    "    request = Request(request_str)\n",
    "    res = requests.get(request_str)\n",
    "    distance = json.loads(res.text)['paths'][0]['distance']\n",
    "    time = json.loads(res.text)['paths'][0]['time']\n",
    "    minute, msec = divmod(time, 60000) \n",
    "    return distance / 1609.344 , minute + (msec / 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pairs(node_a,node_b,trip_type):\n",
    "    if trip_type == 1:\n",
    "        #Combination LGA--> a -->b\n",
    "        #if no distance call graphhopper \n",
    "        LGA_a_dist = df_distance.loc[(node_a.pickup_location[2],node_a.dropoff_location[2])]['distance']\n",
    "        a_b_dist = df_distance.loc[(node_a.dropoff_location[2],node_b.dropoff_location[2])]['distance']\n",
    "        LGA_a_dur = df_distance.loc[(node_a.pickup_location[2],node_a.dropoff_location[2])]['duration']\n",
    "        a_b_dur = df_distance.loc[(node_a.dropoff_location[2],node_b.dropoff_location[2])]['duration']\n",
    "        \n",
    "        #Combination LGA--> b -->a\n",
    "        LGA_b_dist = df_distance.loc[(node_b.pickup_location[2],node_b.dropoff_location[2])]['distance']\n",
    "        b_a_dist = df_distance.loc[(node_b.dropoff_location[2],node_a.dropoff_location[2])]['distance']\n",
    "        LGA_b_dur = df_distance.loc[(node_b.pickup_location[2],node_b.dropoff_location[2])]['duration']\n",
    "        b_a_dur = df_distance.loc[(node_b.dropoff_location[2],node_a.dropoff_location[2])]['duration']\n",
    "        \n",
    "        path_1_total_dis,path_1_total_dur = LGA_a_dist + a_b_dist,LGA_a_dur + a_b_dur \n",
    "        path_1_a_dur,path_1_b_dur = LGA_a_dur,path_1_total_dur\n",
    "        \n",
    "        path_2_total_dis,path_2_total_dur = LGA_b_dist+b_a_dist,LGA_b_dur+b_a_dur\n",
    "        path_2_a_dur,path_2_b_dur         = path_2_total_dur ,LGA_b_dur\n",
    "               \n",
    "    else:\n",
    "        \n",
    "        if (node_a.pickup_location[2],node_b.pickup_location[2]) not in df_distance.index:\n",
    "            a_b_distance,a_b_duration = get_distance_duration(node_a,node_b,2)\n",
    "        else:\n",
    "            a_b_distance = df_distance.loc[(node_a.pickup_location[2],node_b.pickup_location[2])]['distance']\n",
    "            a_b_duration = df_distance.loc[(node_a.pickup_location[2],node_b.pickup_location[2])]['duration']\n",
    "        \n",
    "        #Combination a--> b --> LGA\n",
    "        a_b_dist   = a_b_distance\n",
    "        b_LGA_dist = node_b.distance \n",
    "        a_b_dur    = a_b_duration\n",
    "        b_LGA_dur  = node_b.duration\n",
    "        \n",
    "        if (node_b.pickup_location[2],node_a.pickup_location[2]) not in df_distance.index:\n",
    "            b_a_distance,b_a_duration = get_distance_duration(node_b,node_a,2)\n",
    "        else:\n",
    "            b_a_distance = df_distance.loc[(node_b.pickup_location[2],node_a.pickup_location[2])]['distance']\n",
    "            b_a_duration = df_distance.loc[(node_b.pickup_location[2],node_a.pickup_location[2])]['duration']\n",
    "        \n",
    "        #Combination b--> a --> LGA\n",
    "        b_a_dist   = b_a_distance\n",
    "        a_LGA_dist = node_a.distance \n",
    "        b_a_dur    = b_a_duration\n",
    "        a_LGA_dur  = node_a.duration\n",
    "        \n",
    "        path_1_total_dis,path_1_total_dur = a_b_dist + b_LGA_dist,a_b_dur + b_LGA_dur \n",
    "        path_1_a_dur,path_1_b_dur = path_1_total_dur,b_LGA_dur\n",
    "        \n",
    "        path_2_total_dis,path_2_total_dur, = b_a_dist+a_LGA_dist,b_a_dur+a_LGA_dur\n",
    "        path_2_a_dur,path_2_b_dur         = a_LGA_dur,path_2_total_dur\n",
    "        \n",
    "    return ((path_1_total_dis,path_1_total_dur,path_1_a_dur,path_1_b_dur),( path_2_total_dis,path_2_total_dur,path_2_a_dur,path_2_b_dur))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_weight(node_a,node_b):\n",
    "    path1,path2 = get_all_pairs(node_a,node_b,2)\n",
    "    minimum_distance = float('inf')\n",
    "    for path in (path1,path2):\n",
    "        distance_contraint = (path[0] <= node_a.distance + node_b.distance)\n",
    "        delay_constraint = (path[2] <= node_a.duration + node_a.delay) & (path[3] <= node_b.duration + node_b.delay)\n",
    "        #add social constraint too...\n",
    "        \n",
    "        \n",
    "        if distance_contraint and delay_constraint and path[0]< minimum_distance:\n",
    "            minimum_distance = path[0]\n",
    "    distance_saved = node_a.distance + node_b.distance - minimum_distance\n",
    "    return distance_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsg(G):\n",
    "    for node_a,node_b in list(combinations(G,2)):\n",
    "        if (node_a.passenger_count+node_b.passenger_count)<=4:\n",
    "            distance_saved = calculate_edge_weight(node_a,node_b)\n",
    "            if distance_saved!= float('-inf') :\n",
    "                G.add_edge(node_a,node_b, weight=distance_saved)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Average distance saved per pool as a % of total distance of individual rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_distance_saved(merged_trips,Final_Graph):\n",
    "    with_sharing , without_sharing = [],[]\n",
    "    for i in range(len(merged_trips)):\n",
    "        all_nodes =  set()\n",
    "        total_dis_before_merging = 0\n",
    "        total_dis_after_merging = 0\n",
    "        for each_node in Final_Graph[i].nodes:\n",
    "            total_dis_before_merging += each_node.distance\n",
    "            all_nodes.add(each_node)\n",
    "        #remove merged nodes from orginal rga graph\n",
    "        for u,v in merged_trips[i].edges:\n",
    "            all_nodes.remove(u)\n",
    "            all_nodes.remove(v)\n",
    "            total_dis_after_merging += Final_Graph[i].get_edge_data(u,v)['weight']\n",
    "        #add unmerged solo trips also\n",
    "        for solo in all_nodes:\n",
    "            total_dis_after_merging += solo.distance\n",
    "        with_sharing.append(total_dis_after_merging)\n",
    "        without_sharing.append(total_dis_before_merging)\n",
    "\n",
    "    return(sum([(1-x/y) for x, y in zip(with_sharing, without_sharing)])/len(without_sharing) * 100)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average number of trips saved per pool as a % of number of individual trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_trip_saved(merged_trips,Final_Graph):\n",
    "    saved_rides = []\n",
    "    for idx in range(len(Final_Graph)):\n",
    "        num_ind_trips = len(Final_Graph[idx].nodes)\n",
    "        num_pooled_trips = len(merged_trips[idx].edges)\n",
    "        saved_rides.append(num_pooled_trips/num_ind_trips * 100)\n",
    "    return(sum(saved_rides)/len(saved_rides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_algoritm():\n",
    "    Final_Graph = []\n",
    "    for _,trips in df.groupby(['pool_window']):\n",
    "        nodes = []\n",
    "        trips = trips.reset_index()\n",
    "        for idx, row in trips.iterrows():\n",
    "            nodes.append(Node(idx,trips.iloc[idx]))\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        Final_Graph.append(G)\n",
    "\n",
    "    #Start of the code\n",
    "    merged_trips = []\n",
    "    cn=0\n",
    "    for individual_graph in Final_Graph:\n",
    "        ride_sharing_graph = get_rsg(individual_graph)\n",
    "        #maximum weighted algorithm\n",
    "        maximum_weighted_graph = nx.max_weight_matching(ride_sharing_graph, maxcardinality=True)\n",
    "        g_match = nx.Graph()\n",
    "        for u,v in maximum_weighted_graph:\n",
    "            g_match.add_edge(u,v)\n",
    "\n",
    "        merged_trips.append(g_match)\n",
    "    average_distance_saved = Average_distance_saved(merged_trips,Final_Graph)\n",
    "    average_trip_saved = Average_trip_saved(merged_trips,Final_Graph)\n",
    "    print(\"Average distance saved for poolwindow {} is :{}\".format(pool_time_window,average_distance_saved))\n",
    "    print(\"Average trip saved for poolwindow {} is :{}\".format(pool_time_window,average_trip_saved))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main algorithm\n",
      "Average distance saved for poolwindow 5 is :38.81350103988385\n",
      "Average trip saved for poolwindow 5 is :35.59553395684193\n",
      "algorithm time taken for 5 pool window is :57.616408824920654\n",
      "Starting main algorithm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def ceil_dt(dt, delta):\n",
    "        return datetime.min + math.ceil((dt - datetime.min) / delta) * delta\n",
    "\n",
    "df = pd.read_csv('Data/LaGuardia_Dropoff_Final.csv')\n",
    "start_date='2016-05-17 00:00:00'\n",
    "end_date='2016-05-17 23:59:59'\n",
    "columns = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','passenger_count',\\\n",
    "       'trip_distance', 'pickup_longitude','pickup_latitude','dropoff_longitude', 'dropoff_latitude']\n",
    "df = df[columns]\n",
    "df.rename(columns={'tpep_pickup_datetime':'pickup_time',\n",
    "       'tpep_dropoff_datetime':'dropoff_time'},inplace=True)\n",
    "drop_index=df[(df.pickup_latitude==0)|(df.pickup_longitude==0)].index\n",
    "df.drop(drop_index,inplace=True)\n",
    "df['pickup_time'] = pd.to_datetime(df['pickup_time'])\n",
    "df['dropoff_time'] = pd.to_datetime(df['dropoff_time'])\n",
    "df['pickup_h3'] = df.apply(lambda x: h3.geo_to_h3(x['pickup_latitude'], x['pickup_longitude'], 10), axis=1)\n",
    "df['dropoff_h3'] = df.apply(lambda x: h3.geo_to_h3(x['dropoff_latitude'], x['dropoff_longitude'], 8), axis=1)\n",
    "\n",
    "df=df[(df['pickup_time'] >= start_date) & (df['dropoff_time'] <= end_date)]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df['duration'] = (df['pickup_time']-df['dropoff_time']).dt.seconds\n",
    "df['delay'] = df['duration'].apply(lambda x: x*0.20)\n",
    "\n",
    "\n",
    "for pool_time_window in (5,10):\n",
    "    df['pool_window'] = df['pickup_time'].apply(lambda x: ceil_dt(x.to_pydatetime(), timedelta(minutes=pool_time_window)))\n",
    "    df_distance = get_distance(pool_time_window,df)\n",
    "    print(\"Starting main algorithm\")\n",
    "    start_time = time.time()\n",
    "    main_algoritm()\n",
    "    total_time = time.time()-start_time\n",
    "    print(\"algorithm time taken for {} pool window is :{}\\n\".format(pool_time_window,total_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
