{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from h3 import h3\n",
    "import json\n",
    "from urllib.request import URLError, Request, urlopen\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/LaGuardia_Dropoff_Final.csv')\n",
    "columns = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','passenger_count',\\\n",
    "           'trip_distance', 'pickup_longitude','pickup_latitude','dropoff_longitude', 'dropoff_latitude']\n",
    "df = df[columns]\n",
    "df.rename(columns={'tpep_pickup_datetime':'pickup_time',\n",
    "       'tpep_dropoff_datetime':'dropoff_time'},inplace=True)\n",
    "drop_index=df[(df.pickup_latitude==0)|(df.pickup_longitude==0)].index\n",
    "df.drop(drop_index,inplace=True)\n",
    "df['pickup_time'] = pd.to_datetime(df['pickup_time'])\n",
    "df['dropoff_time'] = pd.to_datetime(df['dropoff_time'])\n",
    "df['pickup_h3'] = df.apply(lambda x: h3.geo_to_h3(x['pickup_latitude'], x['pickup_longitude'], 8), axis=1)\n",
    "df['dropoff_h3'] = df.apply(lambda x: h3.geo_to_h3(x['dropoff_latitude'], x['dropoff_longitude'], 10), axis=1)\n",
    "\n",
    "\n",
    "start_date = '2015-09-01 08:00:00' # Start date with time\n",
    "end_date = '2015-09-01 23:59:59' # End date with time\n",
    "df=df[(df['pickup_time'] >= start_date) & (df['dropoff_time'] <= end_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation steps\n",
    "\n",
    "\n",
    "### 1.Install the latest JRE and get GraphHopper Server as zip from <a href=https://graphhopper.com/public/releases/graphhopper-web-0.10.3-bin.zip>Graphhopper API</a>. Unzip it.\n",
    "### 2.Copy this OSM file into the SAME unzipped directory: <a href=https://download.geofabrik.de/north-america/us/new-york-latest.osm.pbf >new-york-latest.osm.pbf</a>\n",
    "### 3.Start GraphHopper Maps via: java -jar graphhopper-web-0.10.3-with-dep.jar jetty.resourcebase=webapp config=config-example.properties datareader.file=new-york-latest.osm.pbf. \n",
    "### 3.Test to see if its running after you see 'Started server at HTTP 8989' by going to http://localhost:8989/ and you should see a map of New York.\n",
    "### 4.Keep this running when executing our program because this is the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance = 17246.857\n",
      "Time = 1100944\n"
     ]
    }
   ],
   "source": [
    "# Check how graphhopper works\n",
    "a,b,c,d = df['pickup_latitude'].loc[474240],df['pickup_longitude'].loc[474240],df['dropoff_latitude'].loc[474240],df['dropoff_longitude'].loc[474240]\n",
    "request_str = 'http://localhost:8989/route?point=' + str(a) + '%2C' + str(b) + '&point=' + str(c) + '%2C' + str(d) + '&vehicle=car'\n",
    "request = Request(request_str)\n",
    "res=requests.get(request_str)\n",
    "print(\"Distance = {}\".format(json.loads(res.text)['paths'][0]['distance']))\n",
    "print(\"Time = {}\".format(json.loads(res.text)['paths'][0]['time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To calculate pool_window.\n",
    "## The dataframe will be divided into pools.We run algorithm for each of these pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceil_dt(dt, delta):\n",
    "    return datetime.min + math.ceil((dt - datetime.min) / delta) * delta\n",
    "\n",
    "pool_time_window = 10 # Change pool time window\n",
    "df['pool_window'] = df['pickup_time'].apply(lambda x: ceil_dt(x.to_pydatetime(), timedelta(minutes=pool_time_window)))\n",
    "df['duration'] = (df['pickup_time']-df['dropoff_time']).dt.seconds\n",
    "df['delay'] = df['duration'].apply(lambda x: x*0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is expected to be calculated and stored in a csv file. Later loaded into a dataframe before running the algorithm.The columns that should be stored in the csv files are same as following dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The nodes of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,idx,data):\n",
    "        self.id = idx\n",
    "        self.pickup_location = (data.pickup_latitude,data.pickup_longitude,data.pickup_h3)\n",
    "        self.dropoff_location = (data.dropoff_latitude,data.dropoff_longitude,data.dropoff_h3)\n",
    "        self.pickup_time = data.pickup_time\n",
    "        self.dropoff_time = data.dropoff_time\n",
    "        self.distance = data.trip_distance\n",
    "        self.duration = data.duration\n",
    "        self.delay = data.delay\n",
    "        #TBD.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try with a sample of 4 trips going to LGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a toy distance df for the above sample dataframe.Note: Since the 'Data/LaGuardia_Dropoff_Final.csv' corresponds to LGA as destination we need only the distance between the pickup of individual trips.\n",
    "\n",
    "## For trips going from LGA we would be needing distance between dropoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,d,e=[],[],[],[]\n",
    "from random import random\n",
    "# creating toy distance to run algorithm\n",
    "for node_a,node_b in list(permutations(sample.index,2)):\n",
    "    a.append(sample.iloc[node_a]['pickup_h3'])\n",
    "    b.append(sample.iloc[node_b]['pickup_h3'])\n",
    "    d.append(round(random(),2))\n",
    "    e.append(round(random(),2))\n",
    "df_distance['pickup_h3'] = a\n",
    "df_distance['dropoff_h3'] = b\n",
    "df_distance['distance'] = d\n",
    "df_distance['duration'] = e\n",
    "df_distance = df_distance.set_index(['pickup_h3','dropoff_h3'])\n",
    "df_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1661cb0b42d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtemp_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pickup_h3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     e, f, g, h = df.iloc[node_a]['pickup_latitude'], df.iloc[node_a]['pickup_longitude'], df.iloc[node_b][\n\u001b[0m\u001b[1;32m     11\u001b[0m         'pickup_latitude'], \\\n\u001b[1;32m     12\u001b[0m                  \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pickup_longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2093\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# a scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'iloc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         return (super(Int64Index, self)\n\u001b[0m\u001b[1;32m    187\u001b[0m                 ._convert_scalar_indexer(key, kind=kind))\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "a,b,c,d=[],[],[],[]\n",
    "df_distance =  pd.DataFrame(columns = ['pickup_h3','dropoff_h3','distance','duration'])\n",
    "for node_a, node_b in list(permutations(df.index, 2)):\n",
    "    temp_curr, temp_next = [], []\n",
    "    temp_curr = df.loc[node_a]['pickup_h3']\n",
    "    temp_next = df.loc[node_b]['pickup_h3']\n",
    "\n",
    "    e, f, g, h = df.iloc[node_a]['pickup_latitude'], df.iloc[node_a]['pickup_longitude'], df.iloc[node_b][\n",
    "        'pickup_latitude'], \\\n",
    "                 df.iloc[node_b]['pickup_longitude']\n",
    "    request_str = 'http://localhost:8989/route?point=' + str(e) + '%2C' + str(f) + '&point=' + str(\n",
    "        g) + '%2C' + str(h) + '&vehicle=car'\n",
    "    request = Request(request_str)\n",
    "    res = requests.get(request_str)\n",
    "    distance = json.loads(res.text)['paths'][0]['distance']\n",
    "    # threshold =\n",
    "    # if distance > threshold:\n",
    "    #     continue;\n",
    "    # NOTE: if you want to use geopy\n",
    "    #      geopy.distance.geodesic(loc1, loc2).miles where\n",
    "    #        [loc1, loc2] =\n",
    "    #               [(df.iloc[node_a]['pickup_latitude'], df.iloc[node_a]['pickup_longitude']),\n",
    "    #                 (df.iloc[node_b]['pickup_latitude'], df.iloc[node_b]['pickup_longitude'])]\n",
    "\n",
    "    time = json.loads(res.text)['paths'][0]['time']\n",
    "    minute, msec = divmod(time, 60000)\n",
    "    a.append(temp_curr)\n",
    "    b.append(temp_next)\n",
    "    c.append(distance / 1609.344)  # convert meters to miles\n",
    "    d.append(minute + (msec / 100000))  # convert ms to s and add to min\n",
    "\n",
    "df_distance['pickup_h3'] = a\n",
    "df_distance['dropoff_h3'] = b\n",
    "df_distance['distance'] = c\n",
    "df_distance['duration'] = d\n",
    "df_distance = df_distance.set_index(['pickup_h3','dropoff_h3'])\n",
    "print('time taken = {}'.format(time.time()-start))\n",
    "df_distance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pairs(node_a,node_b,trip_type):\n",
    "    if trip_type == 1:\n",
    "        #Combination LGA--> a -->b\n",
    "        #if no distance call graphhopper \n",
    "        LGA_a_dist = df_distance.loc[(node_a.pickup_location[2],node_a.dropoff_location[2])]['distance']\n",
    "        a_b_dist = df_distance.loc[(node_a.dropoff_location[2],node_b.dropoff_location[2])]['distance']\n",
    "        LGA_a_dur = df_distance.loc[(node_a.pickup_location[2],node_a.dropoff_location[2])]['duration']\n",
    "        a_b_dur = df_distance.loc[(node_a.dropoff_location[2],node_b.dropoff_location[2])]['duration']\n",
    "        \n",
    "        #Combination LGA--> b -->a\n",
    "        LGA_b_dist = df_distance.loc[(node_b.pickup_location[2],node_b.dropoff_location[2])]['distance']\n",
    "        b_a_dist = df_distance.loc[(node_b.dropoff_location[2],node_a.dropoff_location[2])]['distance']\n",
    "        LGA_b_dur = df_distance.loc[(node_b.pickup_location[2],node_b.dropoff_location[2])]['duration']\n",
    "        b_a_dur = df_distance.loc[(node_b.dropoff_location[2],node_a.dropoff_location[2])]['duration']\n",
    "        \n",
    "        path_1_total_dis,path_1_total_dur = LGA_a_dist + a_b_dist,LGA_a_dur + a_b_dur \n",
    "        path_1_a_dur,path_1_b_dur = LGA_a_dur,path_1_total_dur\n",
    "        \n",
    "        path_2_total_dis,path_2_total_dur = LGA_b_dist+b_a_dist,LGA_b_dur+b_a_dur\n",
    "        path_2_a_dur,path_2_b_dur         = path_2_total_dur ,LGA_b_dur\n",
    "               \n",
    "    else:\n",
    "        #Combination a--> b --> LGA\n",
    "        a_b_dist = df_distance.loc[(node_a.pickup_location[2],node_b.pickup_location[2])]['distance']\n",
    "        b_LGA_dist = node_b.distance \n",
    "        a_b_dur = df_distance.loc[(node_a.pickup_location[2],node_b.pickup_location[2])]['duration']\n",
    "        b_LGA_dur = node_b.duration\n",
    "        \n",
    "        #Combination b--> a --> LGA\n",
    "        b_a_dist = df_distance.loc[(node_b.pickup_location[2],node_a.pickup_location[2])]['distance']\n",
    "        a_LGA_dist = node_a.distance \n",
    "        b_a_dur = df_distance.loc[(node_b.pickup_location[2],node_a.pickup_location[2])]['duration']\n",
    "        a_LGA_dur = node_a.duration\n",
    "        \n",
    "        path_1_total_dis,path_1_total_dur = a_b_dist + b_LGA_dist,a_b_dur + b_LGA_dur \n",
    "        path_1_a_dur,path_1_b_dur = path_1_total_dur,b_LGA_dur\n",
    "        \n",
    "        path_2_total_dis,path_2_total_dur, = b_a_dist+a_LGA_dist,b_a_dur+a_LGA_dur\n",
    "        path_2_a_dur,path_2_b_dur         = a_LGA_dur,path_2_total_dur\n",
    "        \n",
    "    return ((path_1_total_dis,path_1_total_dur,path_1_a_dur,path_1_b_dur),( path_2_total_dis,path_2_total_dur,path_2_a_dur,path_2_b_dur))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_weight(node_a,node_b):\n",
    "    path1,path2 = get_all_pairs(node_a,node_b,2)\n",
    "    minimum_distance = float('inf')\n",
    "    for path in (path1,path2):\n",
    "        distance_contraint = (path[0] <= node_a.distance + node_b.distance)\n",
    "        delay_constraint = (path[2] <= node_a.duration + node_a.delay) & (path[3] <= node_b.duration + node_b.delay)\n",
    "        #add social constraint too...\n",
    "        \n",
    "        \n",
    "        if distance_contraint and delay_constraint and path[0]< minimum_distance:\n",
    "            minimum_distance = path[0]\n",
    "    distance_saved = node_a.distance + node_b.distance - minimum_distance\n",
    "    return distance_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsg(G):\n",
    "    for node_a,node_b in list(combinations(G,2)):\n",
    "        distance_saved = calculate_edge_weight(node_a,node_b)\n",
    "        if distance_saved!= float('inf'):\n",
    "            G.add_edge(node_a,node_b, weight=distance_saved)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the algorithm for sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for _,trips in sample.groupby(['pool_window']):\n",
    "    nodes = []\n",
    "    trips = trips.reset_index()\n",
    "    for idx, row in trips.iterrows():\n",
    "        nodes.append(Node(idx,trips.iloc[idx]))\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    graphs.append(G)\n",
    "    \n",
    "#Start of the code\n",
    "weight_matches = []\n",
    "for g in graphs:\n",
    "    ride_sharing_graph = get_rsg(g)\n",
    "    #maximum weighted algorithm\n",
    "    match = nx.max_weight_matching(ride_sharing_graph, maxcardinality=True)\n",
    "    g_match = nx.Graph()\n",
    "    for u,v in match:\n",
    "        g_match.add_edge(u,v)\n",
    "        \n",
    "    weight_matches.append(g_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selected edges by maximum weight algorithm\")\n",
    "for u,v in weight_matches[0].edges:\n",
    "    print(u.id,v.id,ride_sharing_graph.get_edge_data(u,v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
