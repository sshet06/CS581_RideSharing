{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from h3 import h3\n",
    "import json\n",
    "from urllib.request import URLError, Request, urlopen\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation steps\n",
    "\n",
    "\n",
    " 1.Install the latest JRE and get GraphHopper Server as zip from <a href=https://graphhopper.com/public/releases/graphhopper-web-0.10.3-bin.zip>Graphhopper API</a>. Unzip it.\n",
    "\n",
    "\n",
    "2.Copy this OSM file into the SAME unzipped directory: <a href=https://download.geofabrik.de/north-america/us/new-york-latest.osm.pbf >new-york-latest.osm.pbf</a>\n",
    "\n",
    "\n",
    "3.Start GraphHopper Maps via: java -jar graphhopper-web-0.10.3-with-dep.jar jetty.resourcebase=webapp config=config-example.properties datareader.file=new-york-latest.osm.pbf. \n",
    "\n",
    "\n",
    "4.Test to see if its running after you see 'Started server at HTTP 8989' by going to http://localhost:8989/ and you should see a map of New York.\n",
    "\n",
    "\n",
    "5.Keep this running when executing our program because this is the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance = 10640.72\n",
      "Time = 627064\n"
     ]
    }
   ],
   "source": [
    "# Check if graphhopper works\n",
    "request_str = 'http://localhost:8989/route?point=' + str(40.760166) + '%2C' + str(-73.964760) + '&point=' + str(40.768780) + '%2C' + str(-73.867058) + '&vehicle=car'\n",
    "request = Request(request_str)\n",
    "res=requests.get(request_str)\n",
    "print(\"Distance = {}\".format(json.loads(res.text)['paths'][0]['distance']))\n",
    "print(\"Time = {}\".format(json.loads(res.text)['paths'][0]['time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The nodes of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,idx,data):\n",
    "        self.id = idx\n",
    "        self.pickup_location = (data.pickup_latitude,data.pickup_longitude,data.pickup_h3)\n",
    "        self.dropoff_location = (data.dropoff_latitude,data.dropoff_longitude,data.dropoff_h3)\n",
    "        self.pickup_time = data.pickup_time\n",
    "        self.dropoff_time = data.dropoff_time\n",
    "        self.distance = data.trip_distance\n",
    "        self.duration = data.duration\n",
    "        self.delay = data.delay\n",
    "        self.passenger_count = data.passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_duration(node_a,node_b,trip_type):\n",
    "    if trip_type==2: \n",
    "        e, f, g, h = node_a.pickup_location[0], node_a.pickup_location[1], node_b.pickup_location[0],node_b.pickup_location[1]\n",
    "    else:\n",
    "        e, f, g, h = node_a.dropoff_location[0], node_a.dropoff_location[1], node_b.dropoff_location[0],node_b.dropoff_location[1]\n",
    "    request_str = 'http://localhost:8989/route?point=' + str(e) + '%2C' + str(f) + '&point=' + str(\n",
    "        g) + '%2C' + str(h) + '&vehicle=car'\n",
    "    request = Request(request_str)\n",
    "    res = requests.get(request_str)\n",
    "    if 'paths' in json.loads(res.text):\n",
    "        distance = json.loads(res.text)['paths'][0]['distance']\n",
    "        time = json.loads(res.text)['paths'][0]['time']\n",
    "        minute, msec = divmod(time, 60000)\n",
    "        return distance / 1609.344 , minute + (msec / 100000)\n",
    "    else:\n",
    "        return float('inf'),float('inf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pairs(node_a,node_b,trip_type):\n",
    "    if trip_type == 1:\n",
    "        #Combination LGA--> a -->b\n",
    "        #if no distance call graphhopper \n",
    "        if (node_a.dropoff_location[2],node_b.dropoff_location[2]) not in df_distance.index:\n",
    "            a_b_distance,a_b_duration = get_distance_duration(node_a,node_b,trip_type)\n",
    "        else:\n",
    "            a_b_distance = df_distance.loc[(node_a.dropoff_location[2],node_b.dropoff_location[2])]['distance']\n",
    "            a_b_duration = df_distance.loc[(node_a.dropoff_location[2],node_b.dropoff_location[2])]['duration']\n",
    "        \n",
    "        LGA_a_dist = node_a.distance\n",
    "        a_b_dist   = a_b_distance\n",
    "        LGA_a_dur  = node_a.duration\n",
    "        a_b_dur    = a_b_duration\n",
    "        \n",
    "        #Combination LGA--> b -->a\n",
    "        if (node_b.dropoff_location[2],node_a.dropoff_location[2]) not in df_distance.index:\n",
    "            b_a_distance,b_a_duration = get_distance_duration(node_a,node_b,trip_type)\n",
    "        else:\n",
    "            b_a_distance = df_distance.loc[(node_b.dropoff_location[2],node_a.dropoff_location[2])]['distance']\n",
    "            b_a_duration = df_distance.loc[(node_b.dropoff_location[2],node_a.dropoff_location[2])]['duration']\n",
    "            \n",
    "        LGA_b_dist = node_b.distance\n",
    "        b_a_dist = b_a_distance\n",
    "        LGA_b_dur = node_b.duration\n",
    "        b_a_dur = b_a_duration\n",
    "        \n",
    "        path_1_total_dis,path_1_total_dur = LGA_a_dist + a_b_dist,LGA_a_dur + a_b_dur \n",
    "        path_1_a_dur,path_1_b_dur = LGA_a_dur,path_1_total_dur\n",
    "        \n",
    "        path_2_total_dis,path_2_total_dur = LGA_b_dist+b_a_dist,LGA_b_dur+b_a_dur\n",
    "        path_2_a_dur,path_2_b_dur         = path_2_total_dur ,LGA_b_dur\n",
    "               \n",
    "    else:\n",
    "        #Combination a--> b --> LGA\n",
    "        if (node_a.pickup_location[2],node_b.pickup_location[2]) not in df_distance.index:\n",
    "            a_b_distance,a_b_duration = get_distance_duration(node_a,node_b,trip_type)\n",
    "        else:\n",
    "            a_b_distance = df_distance.loc[(node_a.pickup_location[2],node_b.pickup_location[2])]['distance']\n",
    "            a_b_duration = df_distance.loc[(node_a.pickup_location[2],node_b.pickup_location[2])]['duration']\n",
    "        \n",
    "        a_b_dist   = a_b_distance\n",
    "        b_LGA_dist = node_b.distance \n",
    "        a_b_dur    = a_b_duration\n",
    "        b_LGA_dur  = node_b.duration\n",
    "        \n",
    "        #Combination b--> a --> LGA\n",
    "        if (node_b.pickup_location[2],node_a.pickup_location[2]) not in df_distance.index:\n",
    "            b_a_distance,b_a_duration = get_distance_duration(node_b,node_a,trip_type)\n",
    "        else:\n",
    "            b_a_distance = df_distance.loc[(node_b.pickup_location[2],node_a.pickup_location[2])]['distance']\n",
    "            b_a_duration = df_distance.loc[(node_b.pickup_location[2],node_a.pickup_location[2])]['duration']\n",
    "        \n",
    "        b_a_dist   = b_a_distance\n",
    "        a_LGA_dist = node_a.distance \n",
    "        b_a_dur    = b_a_duration\n",
    "        a_LGA_dur  = node_a.duration\n",
    "        \n",
    "        path_1_total_dis,path_1_total_dur = a_b_dist + b_LGA_dist,a_b_dur + b_LGA_dur \n",
    "        path_1_a_dur,path_1_b_dur = path_1_total_dur,b_LGA_dur\n",
    "        \n",
    "        path_2_total_dis,path_2_total_dur, = b_a_dist+a_LGA_dist,b_a_dur+a_LGA_dur\n",
    "        path_2_a_dur,path_2_b_dur         = a_LGA_dur,path_2_total_dur\n",
    "        \n",
    "    return ((path_1_total_dis,path_1_total_dur,path_1_a_dur,path_1_b_dur),( path_2_total_dis,path_2_total_dur,path_2_a_dur,path_2_b_dur))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_weight(node_a,node_b,trip_type):\n",
    "    path1,path2 = get_all_pairs(node_a,node_b,trip_type)\n",
    "    minimum_distance = float('inf')\n",
    "    for path in (path1,path2):\n",
    "        distance_contraint = (path[0] <= node_a.distance + node_b.distance)\n",
    "        delay_constraint = (path[2] <= node_a.duration + node_a.delay) & (path[3] <= node_b.duration + node_b.delay)\n",
    "        #add social constraint too...\n",
    "        \n",
    "        \n",
    "        if distance_contraint and delay_constraint and path[0]< minimum_distance:\n",
    "            minimum_distance = path[0]\n",
    "    distance_saved = node_a.distance + node_b.distance - minimum_distance\n",
    "    return distance_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsg(G,trip_type):\n",
    "    for node_a,node_b in list(combinations(G,2)):\n",
    "        if (node_a.passenger_count+node_b.passenger_count)<=4:\n",
    "            distance_saved = calculate_edge_weight(node_a,node_b,trip_type)\n",
    "            if distance_saved!= float('-inf') :\n",
    "                G.add_edge(node_a,node_b, weight=distance_saved)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Average distance saved per pool as a % of total distance of individual rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_distance_saved(merged_trips,Final_Graph):\n",
    "    with_sharing , without_sharing = [],[]\n",
    "    for i in range(len(merged_trips)):\n",
    "        all_nodes =  set()\n",
    "        total_dis_before_merging = 0\n",
    "        total_dis_after_merging = 0\n",
    "        for each_node in Final_Graph[i].nodes:\n",
    "            total_dis_before_merging += each_node.distance\n",
    "            all_nodes.add(each_node)\n",
    "        #remove merged nodes from orginal rga graph\n",
    "        for u,v in merged_trips[i].edges:\n",
    "            all_nodes.remove(u)\n",
    "            all_nodes.remove(v)\n",
    "            total_dis_after_merging += Final_Graph[i].get_edge_data(u,v)['weight']\n",
    "        #add unmerged solo trips also\n",
    "        for solo in all_nodes:\n",
    "            total_dis_after_merging += solo.distance\n",
    "        with_sharing.append(total_dis_after_merging)\n",
    "        without_sharing.append(total_dis_before_merging)\n",
    "    return(sum([(1-x/y) for x, y in zip(with_sharing, without_sharing)])/len(without_sharing) * 100)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average number of trips saved per pool as a % of number of individual trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_trip_saved(merged_trips,Final_Graph):\n",
    "    saved_rides = []\n",
    "    for idx in range(len(merged_trips)):\n",
    "        num_ind_trips = len(Final_Graph[idx].nodes)\n",
    "        num_pooled_trips = len(merged_trips[idx].edges)\n",
    "        saved_rides.append(num_pooled_trips/num_ind_trips * 100)\n",
    "    return(sum(saved_rides)/len(saved_rides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def main_algoritm(trip_type,excecution_time):\n",
    "    start_execution = time.time()\n",
    "    Final_Graph = []\n",
    "    t = 0\n",
    "    for _,trips in df.groupby(['pool_window']):\n",
    "        nodes = []\n",
    "        trips = trips.reset_index()\n",
    "        for idx, row in trips.iterrows():\n",
    "            nodes.append(Node(idx,trips.iloc[idx]))\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        Final_Graph.append(G)\n",
    "\n",
    "    #Start of the code\n",
    "    merged_trips = []\n",
    "    cn=0\n",
    "    for individual_graph in tqdm(Final_Graph,total=len(Final_Graph)):\n",
    "        if int(excecution_time) > 0 and ((time.time() - start_execution)/60 >= float(excecution_time)):\n",
    "            break\n",
    "        s = time.time()\n",
    "        ride_sharing_graph = get_rsg(individual_graph,trip_type)\n",
    "        #maximum weighted algorithm\n",
    "        maximum_weighted_graph = nx.max_weight_matching(ride_sharing_graph, maxcardinality=True)\n",
    "        g_match = nx.Graph()\n",
    "        for u,v in maximum_weighted_graph:\n",
    "            g_match.add_edge(u,v)\n",
    "\n",
    "        merged_trips.append(g_match)\n",
    "        t += time.time()-s\n",
    "    if int(excecution_time)>0:\n",
    "        print(\"Number of pools processed in {} min :{}\".format(excecution_time,len(merged_trips)))\n",
    "    else:\n",
    "        print(\"Number of pools processed for one day data:{}\".format(len(merged_trips)))\n",
    "    print(\"Average computation time is {} sec\".format(t/len(merged_trips)))\n",
    "    average_distance_saved = Average_distance_saved(merged_trips,Final_Graph)\n",
    "    average_trip_saved = Average_trip_saved(merged_trips,Final_Graph)\n",
    "    print(\"Average distance saved for poolwindow {} is :{}\".format(pool_time_window,average_distance_saved))\n",
    "    print(\"Average trip saved for poolwindow {} is :{}\".format(pool_time_window,average_trip_saved)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM LGA \n",
    "ps (Lots of room for improvement. Please feel free to change any part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter year:2016\n",
      "Enter month:May\n",
      "Enter day:06\n",
      "What input data you want to run:\n",
      " 1.Run one day's data\n",
      " 2.Run the algorithm for given minutes:2\n",
      "Enter excecution time in minutes:7\n",
      "Enter start time in military format (00:00:00):14:00:00\n",
      "\n",
      "Starting main algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1549/12833 [06:13<45:18,  4.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pools processed in 7 min :1549\n",
      "Average computation time is 0.240563657839426 sec\n",
      "Average distance saved for poolwindow 2 is :43.50985580428677\n",
      "Average trip saved for poolwindow 2 is :36.73154641665941\n",
      "algorithm time taken for 2 pool window is :7.024086662133535 minutes\n",
      " \n",
      "\n",
      "Starting main algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 265/3996 [06:23<1:30:03,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pools processed in 7 min :265\n",
      "Average computation time is 1.4476871454490805 sec\n",
      "Average distance saved for poolwindow 7 is :43.46525414927089\n",
      "Average trip saved for poolwindow 7 is :37.856995870803644\n",
      "algorithm time taken for 7 pool window is :7.028175556659699 minutes\n",
      " \n",
      "\n",
      "Starting main algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 61/2859 [06:27<4:56:23,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pools processed in 7 min :61\n",
      "Average computation time is 6.355230792624051 sec\n",
      "Average distance saved for poolwindow 10 is :46.55084112468857\n",
      "Average trip saved for poolwindow 10 is :44.04870835313218\n",
      "algorithm time taken for 10 pool window is :7.026656977335612 minutes\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def ceil_dt(dt, delta):\n",
    "        return datetime.min + math.ceil((dt - datetime.min) / delta) * delta\n",
    "excecution_time = 0\n",
    "mon = dict({'Jan':'01','Feb':'02','Mar':'03','Apr':'04','May':'05','June':'06','July':'07','Aug':'08','Sep':'09',\\\n",
    "            'Oct':'10','Nov':'11','Dec':'12'})\n",
    "year = input(\"Enter year:\")\n",
    "Month = input (\"Enter month:\")\n",
    "day = input(\"Enter day:\")\n",
    "running_type = input(\"What input data you want to run:\\n 1.Run one day's data\\n 2.Run the algorithm for given minutes:\")\n",
    "if running_type == '2':\n",
    "    excecution_time = input(\"Enter excecution time in minutes:\")\n",
    "    strt_time = input(\"Enter start time in military format (00:00:00):\")\n",
    "month = mon[Month]\n",
    "\n",
    "#reading distance and data file\n",
    "file_name = 'Data/LGA as pickup/LaGuardia_as_pickup_'+str(year)+'-'+str(Month)+'.csv'\n",
    "distance_file_name = 'Distance/LGA_as_pickup/'+year+'-'+month+'.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "df_distance = pd.read_csv(distance_file_name)\n",
    "df_distance.drop_duplicates(subset=['pickup_h3','dropoff_h3'],keep=False,inplace=True)\n",
    "df_distance.set_index(['pickup_h3','dropoff_h3'],inplace= True)\n",
    "df_distance = df_distance.sort_index()\n",
    "#######################################################################################################\n",
    "\n",
    "columns = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','passenger_count',\\\n",
    "       'trip_distance', 'pickup_longitude','pickup_latitude','dropoff_longitude', 'dropoff_latitude']\n",
    "df = df[columns]\n",
    "df.rename(columns={'tpep_pickup_datetime':'pickup_time',\n",
    "       'tpep_dropoff_datetime':'dropoff_time'},inplace=True)\n",
    "drop_index=df[(df.pickup_latitude==0)|(df.pickup_longitude==0)|(df.trip_distance==0)].index\n",
    "df.drop(drop_index,inplace=True)\n",
    "df['pickup_time'] = pd.to_datetime(df['pickup_time'])\n",
    "df['dropoff_time'] = pd.to_datetime(df['dropoff_time'])\n",
    "df['pickup_h3'] = df.apply(lambda x: h3.geo_to_h3(x['pickup_latitude'], x['pickup_longitude'], 15), axis=1)\n",
    "df['dropoff_h3'] = df.apply(lambda x: h3.geo_to_h3(x['dropoff_latitude'], x['dropoff_longitude'], 15), axis=1)\n",
    "\n",
    "if running_type =='1':\n",
    "    start_date='2016-'+str(month)+'-'+str(day)+' 00:00:00'\n",
    "    end_date='2016-'+str(month)+'-'+str(day)+' 23:59:59'\n",
    "    df=df[(df['pickup_time'] >= start_date) & (df['dropoff_time'] <= end_date)]\n",
    "else:\n",
    "    start_date='2016-'+str(month)+'-'+str(day)+' '+str(strt_time)\n",
    "    df=df[(df['pickup_time'] >= start_date)]\n",
    "\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df['duration'] = (df['pickup_time']-df['dropoff_time']).dt.seconds\n",
    "df['delay'] = df['duration'].apply(lambda x: x*0.20)\n",
    "\n",
    "\n",
    "for pool_time_window in [2,7,10]:\n",
    "    start_time = time.time()\n",
    "    df['pool_window'] = df['pickup_time'].apply(lambda x: ceil_dt(x.to_pydatetime(), timedelta(minutes=pool_time_window)))\n",
    "    print(\"\\nStarting main algorithm...\")\n",
    "    main_algoritm(1,excecution_time)\n",
    "    total_time = (time.time()-start_time)/60.0\n",
    "    print(\"algorithm time taken for {} pool window is :{} minutes\\n \".format(pool_time_window,total_time))\n",
    "# 20.50257522363784\n",
    "# 39.10754912099276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO LGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting main algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8374/12487 [06:35<03:14, 21.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pools processed in 7 min :8374\n",
      "Average computation time is 0.0470777700190502 sec\n",
      "Average distance saved for poolwindow 2 is :29.437671495761414\n",
      "Average trip saved for poolwindow 2 is :31.75150425557259\n",
      "algorithm time taken for 2 pool window is :7.006277787685394 minutes\n",
      " \n",
      "\n",
      "Starting main algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1006/4335 [06:42<22:11,  2.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pools processed in 7 min :1006\n",
      "Average computation time is 0.3995812778207464 sec\n",
      "Average distance saved for poolwindow 7 is :32.758400908653826\n",
      "Average trip saved for poolwindow 7 is :36.650885660247965\n",
      "algorithm time taken for 7 pool window is :7.013598148028056 minutes\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 608/3175 [06:43<28:22,  1.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting main algorithm...\n",
      "Number of pools processed in 7 min :608\n",
      "Average computation time is 0.6629756724363879 sec\n",
      "Average distance saved for poolwindow 10 is :32.88391380357781\n",
      "Average trip saved for poolwindow 10 is :37.0024875343653\n",
      "algorithm time taken for 10 pool window is :7.017474524180094 minutes\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading distance and data file\n",
    "file_name = 'Data/LGA as dropoff/LaGuardia_as_dropoff_'+str(year)+'-'+str(Month)+'.csv'\n",
    "distance_file_name = 'Distance/LGA_drop_off/'+year+'-'+month+'.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "df_distance = pd.read_csv(distance_file_name)\n",
    "df_distance.drop_duplicates(subset=['pickup_h3','dropoff_h3'],keep=False,inplace=True)\n",
    "df_distance.set_index(['pickup_h3','dropoff_h3'],inplace= True)\n",
    "df_distance = df_distance.sort_index()\n",
    "######################################################################################################\n",
    "\n",
    "columns = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','passenger_count',\\\n",
    "       'trip_distance', 'pickup_longitude','pickup_latitude','dropoff_longitude', 'dropoff_latitude']\n",
    "df = df[columns]\n",
    "df.rename(columns={'tpep_pickup_datetime':'pickup_time','tpep_dropoff_datetime':'dropoff_time'},inplace=True)\n",
    "drop_index=df[(df.pickup_latitude==0)|(df.pickup_longitude==0)|(df.trip_distance==0)].index\n",
    "df.drop(drop_index,inplace=True)\n",
    "df['pickup_time'] = pd.to_datetime(df['pickup_time'])\n",
    "df['dropoff_time'] = pd.to_datetime(df['dropoff_time'])\n",
    "df['pickup_h3'] = df.apply(lambda x: h3.geo_to_h3(x['pickup_latitude'], x['pickup_longitude'], 10), axis=1)\n",
    "df['dropoff_h3'] = df.apply(lambda x: h3.geo_to_h3(x['dropoff_latitude'], x['dropoff_longitude'], 8), axis=1)\n",
    "\n",
    "if running_type =='1':\n",
    "    start_date='2016-'+str(month)+'-'+str(day)+' 00:00:00'\n",
    "    end_date='2016-'+str(month)+'-'+str(day)+' 23:59:59'\n",
    "    df=df[(df['pickup_time'] >= start_date) & (df['dropoff_time'] <= end_date)]\n",
    "else:\n",
    "    start_date='2016-'+str(month)+'-'+str(day)+' '+str(strt_time)\n",
    "    df=df[(df['pickup_time'] >= start_date)]\n",
    "    \n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df['duration'] = (df['pickup_time']-df['dropoff_time']).dt.seconds\n",
    "df['delay'] = df['duration'].apply(lambda x: x*0.20)\n",
    "for pool_time_window in [2,7,10]:\n",
    "    start_time = time.time()\n",
    "    df['pool_window'] = df['pickup_time'].apply(lambda x: ceil_dt(x.to_pydatetime(), timedelta(minutes=pool_time_window)))\n",
    "    print(\"\\nStarting main algorithm...\")\n",
    "    main_algoritm(1,excecution_time)\n",
    "    total_time = (time.time()-start_time)/60.0\n",
    "    print(\"algorithm time taken for {} pool window is :{} minutes\\n \".format(pool_time_window,total_time))\n",
    "# 9.106615776081425\n",
    "# 16.684848484848484"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
